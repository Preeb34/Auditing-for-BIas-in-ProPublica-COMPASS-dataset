{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LK6Xaup-LuPR"
      },
      "source": [
        "**PREPROCESSING TRAIN DATA**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109,
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "ok": true,
              "status": 200,
              "status_text": ""
            }
          }
        },
        "id": "sZjYPXHUlF3x",
        "outputId": "e37cb7ee-0e2c-42be-a8b7-a379ed40e765"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-afb027cb-8a0e-4551-bf76-46c61555cda7\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-afb027cb-8a0e-4551-bf76-46c61555cda7\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving 1643662645_8986752_1567602457_1187546_train_file.csv to 1643662645_8986752_1567602457_1187546_train_file.csv\n",
            "Saving 1643662645_9617953_1567602457_126649_test.csv to 1643662645_9617953_1567602457_126649_test.csv\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r7PTaIobLI1W",
        "outputId": "b6d356ab-56f1-4886-91c2-0fd94c683972"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "      rating  ...                                         lemmatised\n",
            "0         +1  ...  This book life saver . It helpful able go back...\n",
            "1         +1  ...  I buy time old son buy newborn . This super ea...\n",
            "2         +1  ...  This great basic , I wish space write thing bi...\n",
            "3         +1  ...  This book perfect ! Im first time new mom , bo...\n",
            "4         +1  ...  During postpartum stay hospital nurse ask keep...\n",
            "...      ...  ...                                                ...\n",
            "18501     -1  ...  I really like monitor first , second night use...\n",
            "18502     -1  ...  Apparently get pay for . Ive use Philips audio...\n",
            "18503     -1  ...  The old say hold true product `` you get pay f...\n",
            "18504     -1  ...  We great deal research purchase item , love sm...\n",
            "18505     -1  ...  I order great success two package liner discov...\n",
            "\n",
            "[18506 rows x 5 columns]\n"
          ]
        }
      ],
      "source": [
        "#preprocessing and cleaning of training data set\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "import pandas as pd\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize\n",
        "import re\n",
        "\n",
        "file = open('1643662645_8986752_1567602457_1187546_train_file.csv')\n",
        "lines = file.readlines()\n",
        "\n",
        "data = {\"rating\":[],\"review\":[]}\n",
        "\n",
        "#spliting data based on \\t\n",
        "for line in lines:\n",
        "  split_val = line.split('\\t')\n",
        "  data['rating'].append(split_val[0])\n",
        "  data['review'].append(split_val[1])\n",
        "\n",
        "\n",
        "\n",
        "#removing punctuations and numbers\n",
        "df = pd.DataFrame.from_dict(data)\n",
        "\n",
        "remove_punc = lambda sentence: re.sub(re.compile('<.*,?(){}!@#$%^&*_+=[]|\">|[^\\w+]|[0-9]'), ' ', sentence)\n",
        "\n",
        "def cleanhtml(raw_html):\n",
        "  cleanr = re.compile('<.*?>')\n",
        "  cleantext = re.sub(cleanr, '', raw_html)\n",
        "  return cleantext\n",
        "\n",
        "removed_punctuation_list= []\n",
        "for x in df[\"review\"]:\n",
        " cleanString = x.replace('<br>', '').replace('\\'','').replace('-',' ').replace('[\"#\",\"@\",\",\",&\",\":\",\"/\",\"\\\",\"<\",\">\",\"?\",\"\\\\\",\"\\-\\\",\"\\_\\\",\"$\",\".\",\"(\",\")\",\"!\",\"*\",\"~\",\";\",\"{\",\"}\",\"%\",\"^\",\"*\"]',' ').replace('[\"\\'\\\"]','')\n",
        " removed_punctuation_list.append(cleanString.replace('#EOF',''))\n",
        "\n",
        "df[\"removed_punctuations\"] = removed_punctuation_list\n",
        "\n",
        "\n",
        "#stop words removal\n",
        "stop_words = set(stopwords.words('english'))\n",
        "stop_words_removal = lambda x: ' '.join([word for word in x.split() if word not in(stop_words)])\n",
        "df[\"removed_stop_words\"]=df[\"removed_punctuations\"].apply(stop_words_removal)\n",
        "\n",
        "#lemmatization\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "from nltk.corpus import wordnet\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "\n",
        "def pos_tagger(nltk_tag):\n",
        "  if nltk_tag.startswith('J'):\n",
        "    return wordnet.ADJ\n",
        "  elif nltk_tag.startswith('V'):\n",
        "    return wordnet.VERB\n",
        "  elif nltk_tag.startswith('N'):\n",
        "    return wordnet.NOUN\n",
        "  elif nltk_tag.startswith('R'):\n",
        "    return wordnet.ADV\n",
        "  else:\n",
        "    return None\n",
        "  \n",
        "list_lemmatised= []\n",
        "\n",
        "for x in df[\"removed_stop_words\"]:\n",
        "  text_tokens = nltk.pos_tag(nltk.word_tokenize(x)) \n",
        "  wordnet_tagged = list(map(lambda x: (x[0], pos_tagger(x[1])), text_tokens ))\n",
        "  lemmatized_sentence = []\n",
        "  for word,tag in wordnet_tagged:\n",
        "    if tag is None:\n",
        "        lemmatized_sentence.append(word)\n",
        "    else:       \n",
        "        lemmatized_sentence.append(lemmatizer.lemmatize(word, tag))\n",
        "  #tokens_lemmatised = [lemmatizer.lemmatize(word) for word in text_tokens ]\n",
        "  list_lemmatised.append(\" \".join(lemmatized_sentence))\n",
        "\n",
        "df[\"lemmatised\"] = list_lemmatised\n",
        "\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "ADIbF9r_rqR7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 641
        },
        "outputId": "faac7a45-8f46-425f-f2bd-a293bda12a79"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-cdaca6cf-e3b3-4d9d-9abf-6f08e9964f1b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>rating</th>\n",
              "      <th>review</th>\n",
              "      <th>removed_punctuations</th>\n",
              "      <th>removed_stop_words</th>\n",
              "      <th>lemmatised</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>+1</td>\n",
              "      <td>This book is such a life saver.  It has been s...</td>\n",
              "      <td>This book is such a life saver.  It has been s...</td>\n",
              "      <td>This book life saver. It helpful able go back ...</td>\n",
              "      <td>This book life saver . It helpful able go back...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>+1</td>\n",
              "      <td>I bought this a few times for my older son and...</td>\n",
              "      <td>I bought this a few times for my older son and...</td>\n",
              "      <td>I bought times older son bought newborn. This ...</td>\n",
              "      <td>I buy time old son buy newborn . This super ea...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>+1</td>\n",
              "      <td>This is great for basics, but I wish the space...</td>\n",
              "      <td>This is great for basics, but I wish the space...</td>\n",
              "      <td>This great basics, I wish space write things b...</td>\n",
              "      <td>This great basic , I wish space write thing bi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>+1</td>\n",
              "      <td>This book is perfect!  I'm a first time new mo...</td>\n",
              "      <td>This book is perfect!  Im a first time new mom...</td>\n",
              "      <td>This book perfect! Im first time new mom, book...</td>\n",
              "      <td>This book perfect ! Im first time new mom , bo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>+1</td>\n",
              "      <td>During your postpartum stay at the hospital th...</td>\n",
              "      <td>During your postpartum stay at the hospital th...</td>\n",
              "      <td>During postpartum stay hospital nurses ask kee...</td>\n",
              "      <td>During postpartum stay hospital nurse ask keep...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18501</th>\n",
              "      <td>-1</td>\n",
              "      <td>I really liked this monitor at first, but the ...</td>\n",
              "      <td>I really liked this monitor at first, but the ...</td>\n",
              "      <td>I really liked monitor first, second night use...</td>\n",
              "      <td>I really like monitor first , second night use...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18502</th>\n",
              "      <td>-1</td>\n",
              "      <td>Apparently you get what you pay for.  I've use...</td>\n",
              "      <td>Apparently you get what you pay for.  Ive used...</td>\n",
              "      <td>Apparently get pay for. Ive used Philips audio...</td>\n",
              "      <td>Apparently get pay for . Ive use Philips audio...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18503</th>\n",
              "      <td>-1</td>\n",
              "      <td>The old saying holds true with this product --...</td>\n",
              "      <td>The old saying holds true with this product   ...</td>\n",
              "      <td>The old saying holds true product \"you get pay...</td>\n",
              "      <td>The old say hold true product `` you get pay f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18504</th>\n",
              "      <td>-1</td>\n",
              "      <td>We did a great deal of research before purchas...</td>\n",
              "      <td>We did a great deal of research before purchas...</td>\n",
              "      <td>We great deal research purchasing item, loved ...</td>\n",
              "      <td>We great deal research purchase item , love sm...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18505</th>\n",
              "      <td>-1</td>\n",
              "      <td>I ordered these after having great success wit...</td>\n",
              "      <td>I ordered these after having great success wit...</td>\n",
              "      <td>I ordered great success two packages liners di...</td>\n",
              "      <td>I order great success two package liner discov...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>18506 rows × 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cdaca6cf-e3b3-4d9d-9abf-6f08e9964f1b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-cdaca6cf-e3b3-4d9d-9abf-6f08e9964f1b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-cdaca6cf-e3b3-4d9d-9abf-6f08e9964f1b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "      rating  ...                                         lemmatised\n",
              "0         +1  ...  This book life saver . It helpful able go back...\n",
              "1         +1  ...  I buy time old son buy newborn . This super ea...\n",
              "2         +1  ...  This great basic , I wish space write thing bi...\n",
              "3         +1  ...  This book perfect ! Im first time new mom , bo...\n",
              "4         +1  ...  During postpartum stay hospital nurse ask keep...\n",
              "...      ...  ...                                                ...\n",
              "18501     -1  ...  I really like monitor first , second night use...\n",
              "18502     -1  ...  Apparently get pay for . Ive use Philips audio...\n",
              "18503     -1  ...  The old say hold true product `` you get pay f...\n",
              "18504     -1  ...  We great deal research purchase item , love sm...\n",
              "18505     -1  ...  I order great success two package liner discov...\n",
              "\n",
              "[18506 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_CkpiYBEMBSy"
      },
      "source": [
        "**PREPROCESSING TEST DATA**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "CaHskr7iLWft",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32dbe8f1-e413-43fe-809e-b3fbccb61f21"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "                                                  review  ...                                         lemmatised\n",
            "0      Perfect for new parents. We were able to keep ...  ...  Perfect new parent . We able keep track baby f...\n",
            "1      Helps me know exactly how my babies day has go...  ...  Helps know exactly baby day go mother law watc...\n",
            "2      I wanted an alternative to printing out daily ...  ...  I want alternative printing daily log sheet na...\n",
            "3      My 3 month old son spend half of his days with...  ...  My 3 month old son spend half day mother half ...\n",
            "4      The Baby Tracker brand books are the absolute ...  ...  The Baby Tracker brand book absolute best trac...\n",
            "...                                                  ...  ...                                                ...\n",
            "18501  WTF. The pieces don't fit together, the instru...  ...  WTF . The piece dont fit together , instructio...\n",
            "18502  I've gone through a couple of video baby monit...  ...  Ive go couple video baby monitor I compare one...\n",
            "18503  This monitor is cheap and doesn't work well. O...  ...  This monitor cheap doesnt work well . Over hal...\n",
            "18504  These monitors do not work at all, I even atte...  ...  These monitor work all , I even attempt contac...\n",
            "18505  Short story, I was very disappointed with the ...  ...  Short story , I disappoint quality think engin...\n",
            "\n",
            "[18506 rows x 4 columns]\n"
          ]
        }
      ],
      "source": [
        "#preprocessing and cleaning of test data set\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "import re\n",
        "\n",
        "file = open('1643662645_9617953_1567602457_126649_test.csv')\n",
        "lines_test = file.readlines()\n",
        "\n",
        "\n",
        "df_test = {\"review\":[]}\n",
        "\n",
        "for line in lines_test:\n",
        "  df_test['review'].append(line)\n",
        "\n",
        "df_test = pd.DataFrame.from_dict(df_test)\n",
        "\n",
        "\n",
        "list_removed_punctuation= []\n",
        "for x in df_test[\"review\"]:\n",
        " cleanString = x.replace('<br>', '').replace('\\'','').replace('-',' ').replace('[\"#\",\"@\",\"&\",\":\",\"/\",\"\\\",\"<\",\">\",\"?\",\"\\\\\",\"\\-\\\",\"\\_\\\",\"$\",\".\",\"(\",\")\",\"!\",\"*\",\"~\",\";\",\"{\",\"}\",\"%\"]',' ').replace('[\"\\'\\\"]','')\n",
        " list_removed_punctuation.append(cleanString.replace('#EOF',''))\n",
        "\n",
        "\n",
        "df_test[\"removed_punctuations\"] = list_removed_punctuation\n",
        "\n",
        "#stop words removal\n",
        "words = set(stopwords.words('english'))\n",
        "df_test[\"removed_stop_words\"]=df_test[\"removed_punctuations\"].apply(lambda x: ' '.join([word for word in x.split() if word not in(words)]))\n",
        "\n",
        "#lemmatization\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "from nltk.corpus import wordnet\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "\n",
        "def pos_tagger(nltk_tag):\n",
        "  if nltk_tag.startswith('J'):\n",
        "    return wordnet.ADJ\n",
        "  elif nltk_tag.startswith('V'):\n",
        "    return wordnet.VERB\n",
        "  elif nltk_tag.startswith('N'):\n",
        "    return wordnet.NOUN\n",
        "  elif nltk_tag.startswith('R'):\n",
        "    return wordnet.ADV\n",
        "  else:\n",
        "    return None\n",
        "  \n",
        "list_lemmatised= []\n",
        "\n",
        "for x in df_test[\"removed_stop_words\"]:\n",
        "  text_tokens = nltk.pos_tag(nltk.word_tokenize(x)) \n",
        "  wordnet_tagged = list(map(lambda x: (x[0], pos_tagger(x[1])), text_tokens ))\n",
        "  lemmatized_sentence = []\n",
        "  for word,tag in wordnet_tagged:\n",
        "    if tag is None:\n",
        "        lemmatized_sentence.append(word)\n",
        "    else:       \n",
        "        lemmatized_sentence.append(lemmatizer.lemmatize(word, tag))\n",
        "  #tokens_lemmatised = [lemmatizer.lemmatize(word) for word in text_tokens ]\n",
        "  list_lemmatised.append(\" \".join(lemmatized_sentence))\n",
        "\n",
        "df_test[\"lemmatised\"] = list_lemmatised\n",
        "print(df_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "324dxlpnrkB5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 641
        },
        "outputId": "ae4d40b1-9954-4812-8272-6b2b81e537df"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-e2aa518b-f08b-4eb9-a9ab-6da30fdf051f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>removed_punctuations</th>\n",
              "      <th>removed_stop_words</th>\n",
              "      <th>lemmatised</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Perfect for new parents. We were able to keep ...</td>\n",
              "      <td>Perfect for new parents. We were able to keep ...</td>\n",
              "      <td>Perfect new parents. We able keep track babys ...</td>\n",
              "      <td>Perfect new parent . We able keep track baby f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Helps me know exactly how my babies day has go...</td>\n",
              "      <td>Helps me know exactly how my babies day has go...</td>\n",
              "      <td>Helps know exactly babies day gone mother law ...</td>\n",
              "      <td>Helps know exactly baby day go mother law watc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I wanted an alternative to printing out daily ...</td>\n",
              "      <td>I wanted an alternative to printing out daily ...</td>\n",
              "      <td>I wanted alternative printing daily log sheets...</td>\n",
              "      <td>I want alternative printing daily log sheet na...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>My 3 month old son spend half of his days with...</td>\n",
              "      <td>My 3 month old son spend half of his days with...</td>\n",
              "      <td>My 3 month old son spend half days mother half...</td>\n",
              "      <td>My 3 month old son spend half day mother half ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The Baby Tracker brand books are the absolute ...</td>\n",
              "      <td>The Baby Tracker brand books are the absolute ...</td>\n",
              "      <td>The Baby Tracker brand books absolute best tra...</td>\n",
              "      <td>The Baby Tracker brand book absolute best trac...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18501</th>\n",
              "      <td>WTF. The pieces don't fit together, the instru...</td>\n",
              "      <td>WTF. The pieces dont fit together, the instruc...</td>\n",
              "      <td>WTF. The pieces dont fit together, instruction...</td>\n",
              "      <td>WTF . The piece dont fit together , instructio...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18502</th>\n",
              "      <td>I've gone through a couple of video baby monit...</td>\n",
              "      <td>Ive gone through a couple of video baby monito...</td>\n",
              "      <td>Ive gone couple video baby monitors I compared...</td>\n",
              "      <td>Ive go couple video baby monitor I compare one...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18503</th>\n",
              "      <td>This monitor is cheap and doesn't work well. O...</td>\n",
              "      <td>This monitor is cheap and doesnt work well. Ov...</td>\n",
              "      <td>This monitor cheap doesnt work well. Over half...</td>\n",
              "      <td>This monitor cheap doesnt work well . Over hal...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18504</th>\n",
              "      <td>These monitors do not work at all, I even atte...</td>\n",
              "      <td>These monitors do not work at all, I even atte...</td>\n",
              "      <td>These monitors work all, I even attempted cont...</td>\n",
              "      <td>These monitor work all , I even attempt contac...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18505</th>\n",
              "      <td>Short story, I was very disappointed with the ...</td>\n",
              "      <td>Short story, I was very disappointed with the ...</td>\n",
              "      <td>Short story, I disappointed quality thought en...</td>\n",
              "      <td>Short story , I disappoint quality think engin...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>18506 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e2aa518b-f08b-4eb9-a9ab-6da30fdf051f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e2aa518b-f08b-4eb9-a9ab-6da30fdf051f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e2aa518b-f08b-4eb9-a9ab-6da30fdf051f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                  review  ...                                         lemmatised\n",
              "0      Perfect for new parents. We were able to keep ...  ...  Perfect new parent . We able keep track baby f...\n",
              "1      Helps me know exactly how my babies day has go...  ...  Helps know exactly baby day go mother law watc...\n",
              "2      I wanted an alternative to printing out daily ...  ...  I want alternative printing daily log sheet na...\n",
              "3      My 3 month old son spend half of his days with...  ...  My 3 month old son spend half day mother half ...\n",
              "4      The Baby Tracker brand books are the absolute ...  ...  The Baby Tracker brand book absolute best trac...\n",
              "...                                                  ...  ...                                                ...\n",
              "18501  WTF. The pieces don't fit together, the instru...  ...  WTF . The piece dont fit together , instructio...\n",
              "18502  I've gone through a couple of video baby monit...  ...  Ive go couple video baby monitor I compare one...\n",
              "18503  This monitor is cheap and doesn't work well. O...  ...  This monitor cheap doesnt work well . Over hal...\n",
              "18504  These monitors do not work at all, I even atte...  ...  These monitor work all , I even attempt contac...\n",
              "18505  Short story, I was very disappointed with the ...  ...  Short story , I disappoint quality think engin...\n",
              "\n",
              "[18506 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "df_test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yw1BW-mCMDl6"
      },
      "source": [
        "**CREATING MATRIX OF VECTORS**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "HbrZ9nHuLZ_H"
      },
      "outputs": [],
      "source": [
        "import pandas as pd \n",
        "\n",
        "#USING TfidfVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "vectorizer = TfidfVectorizer(max_features=4000)\n",
        "Train_review = vectorizer.fit_transform(df[\"lemmatised\"])\n",
        "Test_review = vectorizer.transform(df_test[\"lemmatised\"])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Train_review"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2f61u7vk0_9G",
        "outputId": "615152cb-fde2-446f-9d8a-9b8156e9a71b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<18506x4000 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 774991 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "Iu1PzzrykrCe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a71580e1-56f2-48fb-de38-8c6781095706"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression()"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import make_classification\n",
        "\n",
        "x_train, x_test, y_train,y_test=train_test_split(Train_review, data['rating'], random_state=1)\n",
        "log_reg = LogisticRegression()\n",
        "log_reg.fit(x_train,y_train)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = log_reg.predict(x_test)"
      ],
      "metadata": {
        "id": "lAPDBqikDEUH"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "print(\"Accuracy:\", accuracy_score(y_test,y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q-Ou2RYwDTyJ",
        "outputId": "68888c88-7fe9-4756-f000-3df36dd3a7fb"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8707585908796196\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "S6-nKhZsDR3x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "y_pred_test = log_reg.predict(Test_review)\n",
        "\n",
        "output = open('./outputAssing.txt', 'w')\n",
        "\n",
        "output.writelines(\"%s \\n\"%i for i in y_pred_test)\n",
        "output.close()"
      ],
      "metadata": {
        "id": "j4DqcL_qEHRD"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4WIHz56A99_7"
      },
      "source": [
        "**Adding data to a text file**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "QsEM3qaB9ZW2"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "neXSJafU9SX0",
        "outputId": "2627f015-a1dd-4347-b3a2-37bc6359894a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "99999"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wurh_0pH9gXr"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "HW1_Bhattacharya.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}